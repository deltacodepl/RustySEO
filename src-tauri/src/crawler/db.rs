use chrono::Utc;
use directories::ProjectDirs;
use rusqlite::{params, Connection, Result};
use serde::{Deserialize, Serialize};
use serde_json;
use std::fs;

mod models;

#[derive(Serialize, Deserialize, Debug)]
pub struct CrawledData {
    pub id: Option<i64>, // Add id as Option to handle inserts where id is not available
    pub url: String,
    pub text: String,
    pub date: String,       // Date as String
    pub title: Vec<String>, // Vector to store as JSON
}

pub fn open_db_connection() -> Result<Connection, rusqlite::Error> {
    // Retrieve the config directory for the application
    let project_dirs = ProjectDirs::from("com", "YourCompany", "YourAppName")
        .ok_or_else(|| rusqlite::Error::QueryReturnedNoRows)?;

    // Define the directory for the DB file
    let db_dir = project_dirs.data_dir(); // Use data_dir() for application data
    let db_path = db_dir.join("crawl_results.db");

    // Ensure the directory exists
    if !db_dir.exists() {
        fs::create_dir_all(db_dir).expect("Failed to create directory");
    }

    // Create a new SQLite database connection
    Connection::open(&db_path)
}

pub fn create_table() -> Result<Connection, rusqlite::Error> {
    let conn = open_db_connection()?;

    // Create the table if it does not exist
    conn.execute(
        "CREATE TABLE IF NOT EXISTS results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            date TEXT,
            url TEXT NOT NULL,
            strategy TEXT,
            performance FLOAT,
            fcp FLOAT,
            lcp FLOAT,
            tti FLOAT,
            tbt FLOAT,
            cls FLOAT,
            dom_size FLOAT,
            speed_index FLOAT,
            server_response_time FLOAT,
            total_byte_weight FLOAT,
            title TEXT
        )",
        [],
    )
    .expect("Failed to create table");
    println!("Table created");
    Ok(conn)
}

pub fn add_crawled_data(url: &str, title: &Vec<String>) -> Result<(), rusqlite::Error> {
    let date = Utc::now().naive_utc().to_string(); // Convert NaiveDateTime to string

    // Serialize the vector as a JSON string
    let title_json = serde_json::to_string(title).expect("Failed to serialize title");

    let conn = create_table()?;

    let data = CrawledData {
        id: None, // ID will be auto-generated by SQLite
        url: url.to_string(),
        text: "Hello, world!".to_string(),
        date,
        title: title.clone(), // No need to convert again
    };

    Ok(())
}

// Function to read data from the database
pub fn read_data_from_db() -> Result<Vec<CrawledData>, rusqlite::Error> {
    let conn = open_db_connection()?;
    let mut stmt = conn.prepare("SELECT * FROM results")?;

    let results = stmt.query_map([], |row| {
        // Deserialize title from JSON string to Vec<String>
        let title_json: String = row.get(5)?;
        let title: Vec<String> =
            serde_json::from_str(&title_json).expect("Failed to deserialize title");

        Ok(CrawledData {
            id: row.get(0)?,
            url: row.get(1)?,
            text: row.get(3)?,
            date: row.get(4)?,
            title,
        })
    })?;

    let mut data = Vec::new();
    for result in results {
        data.push(result?);
    }

    Ok(data)
}

pub fn add_data_from_pagespeed(data: &str, strategy: &str, url: &str) {
    let conn =
        open_db_connection().expect("Failed to open database connection for page speed insights");

    // Attempt to parse the JSON data
    match serde_json::from_str::<models::PageSpeedResponse>(data) {
        Ok(parsed_data) => {
            // Extract response values
            let score = parsed_data.lighthouse_result.categories.performance.score;
            let fcp = parsed_data
                .lighthouse_result
                .audits
                .first_contentful_paint
                .score;
            let lcp = parsed_data
                .lighthouse_result
                .audits
                .largest_contentful_paint
                .score;
            let tti = parsed_data.lighthouse_result.audits.interactive.score;
            let tbt = parsed_data
                .lighthouse_result
                .audits
                .total_blocking_time
                .score;
            let cls = parsed_data
                .lighthouse_result
                .audits
                .cumulative_layout_shift
                .score;
            let dom_size = parsed_data.lighthouse_result.audits.dom_size.display_value;
            let speed_index = parsed_data.lighthouse_result.audits.speed_index.score;
            let server_response_time = parsed_data
                .lighthouse_result
                .audits
                .server_response_time
                .numeric_value;
            let total_byte_weight = parsed_data.lighthouse_result.audits.total_byte_weight.score;
            let performance = format!("{}", score);
            let date = Utc::now().naive_utc().to_string();

            // Attempt to update existing record
            let rows_updated = conn.execute(
                "UPDATE results SET date = ?1, strategy = ?2, performance = ?3, fcp = ?4, lcp = ?5, tti = ?6, tbt = ?7, cls = ?8, dom_size = ?9, speed_index = ?10, server_response_time = ?11, total_byte_weight = ?12 WHERE url = ?13",
                params![date, strategy, performance, fcp, lcp, tti, tbt, cls, dom_size, speed_index, server_response_time, total_byte_weight, url],
            ).expect("Failed to execute update query");

            if rows_updated == 0 {
                // No rows were updated, so insert a new record
                conn.execute(
                    "INSERT INTO results (date, url, strategy, performance, fcp, lcp, tti, tbt, cls, dom_size, speed_index, server_response_time, total_byte_weight) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13)",
                    params![date, url, strategy, performance, fcp, lcp, tti, tbt, cls, dom_size, speed_index, server_response_time, total_byte_weight],
                ).expect("Failed to execute insert query");
            }
        }
        Err(e) => {
            eprintln!("Error parsing JSON: {}", e);
        }
    }
}

pub fn add_page_title_to_db(title: &str, url: &str) {
    let conn = open_db_connection().expect("Failed to open database connection");

    println!("Page title is: {}", title);
    println!("Page url is: {}", url);

    let title_added = conn.execute(
        "INSERT INTO results (url, title) VALUES (?1, ?2)",
        [url, title],
    );

    match title_added {
        Ok(_) => println!("Title added to database"),
        Err(e) => println!("Failed to add title to database: {}", e),
    }
}
