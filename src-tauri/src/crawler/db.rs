use chrono::Utc;
use directories::ProjectDirs;
use rusqlite::{params, Connection, Result};
use serde::{Deserialize, Serialize};
use serde_json;
use std::fs;

mod models;

#[derive(Serialize, Deserialize, Debug)]
pub struct CrawledData {
    pub id: Option<i64>, // Add id as Option to handle inserts where id is not available
    pub url: String,
    pub text: String,
    pub date: String,       // Date as String
    pub title: Vec<String>, // Vector to store as JSON
}

pub fn open_db_connection() -> Result<Connection, rusqlite::Error> {
    // Retrieve the config directory for the application
    let project_dirs = ProjectDirs::from("com", "YourCompany", "YourAppName")
        .ok_or_else(|| rusqlite::Error::QueryReturnedNoRows)?;

    // Define the directory for the DB file
    let db_dir = project_dirs.data_dir(); // Use data_dir() for application data
    let db_path = db_dir.join("crawl_results.db");

    println!("Project directories: {:?}", project_dirs);
    println!("DB directory: {:?}", db_dir);
    println!("DB path: {:?}", db_path);

    // Ensure the directory exists
    if !db_dir.exists() {
        fs::create_dir_all(db_dir).expect("Failed to create directory");
    }

    // Create a new SQLite database connection
    Connection::open(&db_path)
}

pub fn create_table() -> Result<Connection, rusqlite::Error> {
    let conn = open_db_connection()?;

    // Create the table if it does not exist
    conn.execute(
        "CREATE TABLE IF NOT EXISTS results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            date TEXT,
            url TEXT NOT NULL,
            strategy TEXT,
            performance FLOAT,
            fcp FLOAT,
            lcp FLOAT,
            tti FLOAT,
            tbt FLOAT,
            cls FLOAT,
            dom_size FLOAT
        )",
        [],
    )
    .expect("Failed to create table");

    Ok(conn)
}

pub fn add_crawled_data(url: &str, title: &Vec<String>) -> Result<(), rusqlite::Error> {
    let date = Utc::now().naive_utc().to_string(); // Convert NaiveDateTime to string

    // Serialize the vector as a JSON string
    let title_json = serde_json::to_string(title).expect("Failed to serialize title");

    let conn = create_table()?;

    let data = CrawledData {
        id: None, // ID will be auto-generated by SQLite
        url: url.to_string(),
        text: "Hello, world!".to_string(),
        date,
        title: title.clone(), // No need to convert again
    };

    Ok(())
}

// Function to read data from the database
pub fn read_data_from_db() -> Result<Vec<CrawledData>, rusqlite::Error> {
    let conn = open_db_connection()?;
    let mut stmt = conn.prepare("SELECT * FROM results")?;

    let results = stmt.query_map([], |row| {
        // Deserialize title from JSON string to Vec<String>
        let title_json: String = row.get(5)?;
        let title: Vec<String> =
            serde_json::from_str(&title_json).expect("Failed to deserialize title");

        Ok(CrawledData {
            id: row.get(0)?,
            url: row.get(1)?,
            text: row.get(3)?,
            date: row.get(4)?,
            title,
        })
    })?;

    let mut data = Vec::new();
    for result in results {
        data.push(result?);
    }

    Ok(data)
}

pub fn add_data_from_pagespeed(data: &str, strategy: &str, url: &str) {
    let conn =
        open_db_connection().expect("Failed to open database connection for page speed insights");

    match serde_json::from_str::<models::PageSpeedResponse>(data) {
        Ok(mut parsed_data) => {
            println!(
                "Parsed data: {:#?}",
                parsed_data.lighthouse_result.audits.interactive.score
            );
            // BINDING RESPONSE VALUES TO VARIABLES
            let score = parsed_data.lighthouse_result.categories.performance.score;
            let fcp = parsed_data
                .lighthouse_result
                .audits
                .first_contentful_paint
                .score;
            let lcp = parsed_data
                .lighthouse_result
                .audits
                .largest_contentful_paint
                .score;
            let tti = parsed_data.lighthouse_result.audits.interactive.score;
            let tbt = parsed_data
                .lighthouse_result
                .audits
                .total_blocking_time
                .score;
            let cls = parsed_data
                .lighthouse_result
                .audits
                .cumulative_layout_shift
                .score;
            let dom_size = parsed_data.lighthouse_result.audits.dom_size.display_value;
            let performance = format!("{}", score); // Adjust formatting if necessary
            let date = "2024-07-25"; // Use actual date if available

            // Insert data into the results table
            match conn.execute(
                "INSERT INTO results (date, url, strategy, performance, fcp, lcp, tti, tbt, cls, dom_size) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)",
                params![date, url, strategy, performance, fcp, lcp, tti, tbt, cls, dom_size],
            ) {
                Ok(_) => println!("Data added"),
                Err(e) => eprintln!("Failed to insert data: {}", e),
            }
        }
        Err(e) => {
            eprintln!("Error parsing JSON: {}", e);
        }
    }
}
